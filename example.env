### Pick one
COMPOSE_FILE=compose.yml:compose.ports.yml
#COMPOSE_FILE=compose.yml:compose.proxy.yml
#COMPOSE_FILE=compose.yml:compose.ports.yml:compose.gpu.yml
#COMPOSE_FILE=compose.yml:compose.proxy.yml:compose.gpu.yml
#COMPOSE_FILE=compose.yml:compose.proxy.yml:compose.gpu.yml:compose.override.yml

### Models directory on the disk (relative to the docker-compose file)
MODELS_DIR=./models

### Ollama config
OLLAMA_DOMAIN=api.ollama.local # only when proxied
OLLAMA_PORT=11434
OLLAMA_KEEP_ALIVE=15m  # duration to keep models cached in RAM
OLLAMA_LOAD_TIMEOUT=2m # timeout until a request fails. Larger models may need longer initial load times

### OpenWebUI config
WEBUI_DOMAIN=ollama.local # only when proxied
WEBUI_PORT=11444

### Traefik config
TRAEFIK_DOMAIN=traefik.ollama.local # only when proxied

### GPU support (remember to add :compose.gpu.yml to COMPOSE_FILE!)
OLLAMA_GPU_DRIVER=nvidia # or "amd", "intel", etc. if you setup the driver correctly
OLLAMA_GPU_DEVICES=all   # or a list of specific device IDs like "0,1"
